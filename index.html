<!DOCTYPE html>

<!-- HTML file demonstrating Recursive Feature Elimination -->
<html>

	<head>

		<meta charset="ISO-8859-1">



		
		<!-- Website title -->
		<title>RFE</title>




		<!--  Using Google CDN for JQuery -->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>



		<!--  Using Google CDN for JQuery UI -->
		<script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/jquery-ui.js"></script>

		
		
		<!-- Canvas -->
		<script type="text/javascript" src="https://canvasjs.com/assets/script/canvasjs.min.js"></script>
		
		
		
		<!-- CSS -->
		<style type="text/css">
		
			*
			{
				margin: 0;
			}
		
			.header, .footer
			{
				background-color: black;
				color: white;
				font-size: 2em;
				font-weight: bold;
				padding: 20px;
			}
			
			
			
			.sectionMain
			{
				padding: 50px;
			}
			
			.section
			{
				background-color: Beige;
			}
			
			.sectionHeader
			{				
				background-color: grey; 
				color: white;
				padding: 20px;
				font-size: 1.25em;
				font-weight: bold;
			}
			
			.sectionContent
			{
				margin: 50px;
				padding: 20px;
				font-size: 1.25em;
				font-weight: bold;
			}
			
			footer
			{
				padding : 30px;
				font-size: 1.25em;
				font-weight: bold;
				text-align: right;
				background-color: black;
				color: white;
			}
		
		</style>

		


		<!-- Source code for javascript SVM: https://github.com/karpathy/svmjs -->
		<!--  Will be cited in the footer of the webpage. -->
		<script type="text/javascript">
		
			// MIT License
			// Andrej Karpathy
	
			var svmjs = (function(exports){
	
			  /*
			    This is a binary SVM and is trained using the SMO algorithm.
			    Reference: "The Simplified SMO Algorithm" (http://math.unt.edu/~hsp0009/smo.pdf)
			    
			    Simple usage example:
			    svm = svmjs.SVM();
			    svm.train(data, labels);
			    testlabels = svm.predict(testdata);
			  */
			  var SVM = function(options) {
			  }
	
			  SVM.prototype = {
			    
			    // data is NxD array of floats. labels are 1 or -1.
			    train: function(data, labels, options) {
			      
			      // we need these in helper functions
			      this.data = data;
			      this.labels = labels;
	
			      // parameters
			      options = options || {};
			      var C = options.C || 1.0; // C value. Decrease for more regularization
			      var tol = options.tol || 1e-4; // numerical tolerance. Don't touch unless you're pro
			      var alphatol = options.alphatol || 1e-7; // non-support vectors for space and time efficiency are truncated. To guarantee correct result set this to 0 to do no truncating. If you want to increase efficiency, experiment with setting this little higher, up to maybe 1e-4 or so.
			      var maxiter = options.maxiter || 10000; // max number of iterations
			      var numpasses = options.numpasses || 10; // how many passes over data with no change before we halt? Increase for more precision.
			      
			      // instantiate kernel according to options. kernel can be given as string or as a custom function
			      var kernel = linearKernel;
			      this.kernelType = "linear";
			      if("kernel" in options) {
			        if(typeof options.kernel === "string") {
			          // kernel was specified as a string. Handle these special cases appropriately
			          if(options.kernel === "linear") { 
			            this.kernelType = "linear"; 
			            kernel = linearKernel; 
			          }
			          if(options.kernel === "rbf") { 
			            var rbfSigma = options.rbfsigma || 0.5;
			            this.rbfSigma = rbfSigma; // back this up
			            this.kernelType = "rbf";
			            kernel = makeRbfKernel(rbfSigma);
			          }
			        } else {
			          // assume kernel was specified as a function. Let's just use it
			          this.kernelType = "custom";
			          kernel = options.kernel;
			        }
			      }
	
			      // initializations
			      this.kernel = kernel;
			      this.N = data.length; var N = this.N;
			      this.D = data[0].length; var D = this.D;
			      this.alpha = zeros(N);
			      this.b = 0.0;
			      this.usew_ = false; // internal efficiency flag
	
			      // Cache kernel computations to avoid expensive recomputation.
			      // This could use too much memory if N is large.
			      if (options.memoize) {
			        this.kernelResults = new Array(N);
			        for (var i=0;i<N;i++) {
			          this.kernelResults[i] = new Array(N);
			          for (var j=0;j<N;j++) {
			            this.kernelResults[i][j] = kernel(data[i],data[j]);
			          }
			        }
			      }
	
			      // run SMO algorithm
			      var iter = 0;
			      var passes = 0;
			      while(passes < numpasses && iter < maxiter) {
			        
			        var alphaChanged = 0;
			        for(var i=0;i<N;i++) {
			        
			          var Ei= this.marginOne(data[i]) - labels[i];
			          if( (labels[i]*Ei < -tol && this.alpha[i] < C)
			           || (labels[i]*Ei > tol && this.alpha[i] > 0) ){
			            
			            // alpha_i needs updating! Pick a j to update it with
			            var j = i;
			            while(j === i) j= randi(0, this.N);
			            var Ej= this.marginOne(data[j]) - labels[j];
			            
			            // calculate L and H bounds for j to ensure we're in [0 C]x[0 C] box
			            ai= this.alpha[i];
			            aj= this.alpha[j];
			            var L = 0; var H = C;
			            if(labels[i] === labels[j]) {
			              L = Math.max(0, ai+aj-C);
			              H = Math.min(C, ai+aj);
			            } else {
			              L = Math.max(0, aj-ai);
			              H = Math.min(C, C+aj-ai);
			            }
			            
			            if(Math.abs(L - H) < 1e-4) continue;
	
			            var eta = 2*this.kernelResult(i,j) - this.kernelResult(i,i) - this.kernelResult(j,j);
			            if(eta >= 0) continue;
			            
			            // compute new alpha_j and clip it inside [0 C]x[0 C] box
			            // then compute alpha_i based on it.
			            var newaj = aj - labels[j]*(Ei-Ej) / eta;
			            if(newaj>H) newaj = H;
			            if(newaj<L) newaj = L;
			            if(Math.abs(aj - newaj) < 1e-4) continue; 
			            this.alpha[j] = newaj;
			            var newai = ai + labels[i]*labels[j]*(aj - newaj);
			            this.alpha[i] = newai;
			            
			            // update the bias term
			            var b1 = this.b - Ei - labels[i]*(newai-ai)*this.kernelResult(i,i)
			                     - labels[j]*(newaj-aj)*this.kernelResult(i,j);
			            var b2 = this.b - Ej - labels[i]*(newai-ai)*this.kernelResult(i,j)
			                     - labels[j]*(newaj-aj)*this.kernelResult(j,j);
			            this.b = 0.5*(b1+b2);
			            if(newai > 0 && newai < C) this.b= b1;
			            if(newaj > 0 && newaj < C) this.b= b2;
			            
			            alphaChanged++;
			            
			          } // end alpha_i needed updating
			        } // end for i=1..N
			        
			        iter++;
			        //console.log("iter number %d, alphaChanged = %d", iter, alphaChanged);
			        if(alphaChanged == 0) passes++;
			        else passes= 0;
			        
			      } // end outer loop
			      
			      // if the user was using a linear kernel, lets also compute and store the
			      // weights. This will speed up evaluations during testing time
			      if(this.kernelType === "linear") {
	
			        // compute weights and store them
			        this.w = new Array(this.D);
			        for(var j=0;j<this.D;j++) {
			          var s= 0.0;
			          for(var i=0;i<this.N;i++) {
			            s+= this.alpha[i] * labels[i] * data[i][j];
			          }
			          this.w[j] = s;
			          this.usew_ = true;
			        }
			      } else {
	
			        // okay, we need to retain all the support vectors in the training data,
			        // we can't just get away with computing the weights and throwing it out
	
			        // But! We only need to store the support vectors for evaluation of testing
			        // instances. So filter here based on this.alpha[i]. The training data
			        // for which this.alpha[i] = 0 is irrelevant for future. 
			        var newdata = [];
			        var newlabels = [];
			        var newalpha = [];
			        for(var i=0;i<this.N;i++) {
			          //console.log("alpha=%f", this.alpha[i]);
			          if(this.alpha[i] > alphatol) {
			            newdata.push(this.data[i]);
			            newlabels.push(this.labels[i]);
			            newalpha.push(this.alpha[i]);
			          }
			        }
	
			        // store data and labels
			        this.data = newdata;
			        this.labels = newlabels;
			        this.alpha = newalpha;
			        this.N = this.data.length;
			        //console.log("filtered training data from %d to %d support vectors.", data.length, this.data.length);
			      }
	
			      var trainstats = {};
			      trainstats.iters= iter;
			      return trainstats;
			    }, 
			    
			    // inst is an array of length D. Returns margin of given example
			    // this is the core prediction function. All others are for convenience mostly
			    // and end up calling this one somehow.
			    marginOne: function(inst) {
	
			      var f = this.b;
			      // if the linear kernel was used and w was computed and stored,
			      // (i.e. the svm has fully finished training)
			      // the internal class variable usew_ will be set to true.
			      if(this.usew_) {
	
			        // we can speed this up a lot by using the computed weights
			        // we computed these during train(). This is significantly faster
			        // than the version below
			        for(var j=0;j<this.D;j++) {
			          f += inst[j] * this.w[j];
			        }
	
			      } else {
	
			        for(var i=0;i<this.N;i++) {
			          f += this.alpha[i] * this.labels[i] * this.kernel(inst, this.data[i]);
			        }
			      }
	
			      return f;
			    },
			    
			    predictOne: function(inst) { 
			      return this.marginOne(inst) > 0 ? 1 : -1; 
			    },
			    
			    // data is an NxD array. Returns array of margins.
			    margins: function(data) {
			      
			      // go over support vectors and accumulate the prediction. 
			      var N = data.length;
			      var margins = new Array(N);
			      for(var i=0;i<N;i++) {
			        margins[i] = this.marginOne(data[i]);
			      }
			      return margins;
			      
			    },
	
			    kernelResult: function(i, j) {
			      if (this.kernelResults) {
			        return this.kernelResults[i][j];
			      }
			      return this.kernel(this.data[i], this.data[j]);
			    },
	
			    // data is NxD array. Returns array of 1 or -1, predictions
			    predict: function(data) {
			      var margs = this.margins(data);
			      for(var i=0;i<margs.length;i++) {
			        margs[i] = margs[i] > 0 ? 1 : -1;
			      }
			      return margs;
			    },
			    
			    // THIS FUNCTION IS NOW DEPRECATED. WORKS FINE BUT NO NEED TO USE ANYMORE. 
			    // LEAVING IT HERE JUST FOR BACKWARDS COMPATIBILITY FOR A WHILE.
			    // if we trained a linear svm, it is possible to calculate just the weights and the offset
			    // prediction is then yhat = sign(X * w + b)
			    getWeights: function() {
			      
			      // DEPRECATED
			      var w= new Array(this.D);
			      for(var j=0;j<this.D;j++) {
			        var s= 0.0;
			        for(var i=0;i<this.N;i++) {
			          s+= this.alpha[i] * this.labels[i] * this.data[i][j];
			        }
			        w[j]= s;
			      }
			      return {w: w, b: this.b};
			    },
	
			    toJSON: function() {
			      
			      if(this.kernelType === "custom") {
			        console.log("Can't save this SVM because it's using custom, unsupported kernel...");
			        return {};
			      }
	
			      json = {}
			      json.N = this.N;
			      json.D = this.D;
			      json.b = this.b;
	
			      json.kernelType = this.kernelType;
			      if(this.kernelType === "linear") { 
			        // just back up the weights
			        json.w = this.w; 
			      }
			      if(this.kernelType === "rbf") { 
			        // we need to store the support vectors and the sigma
			        json.rbfSigma = this.rbfSigma; 
			        json.data = this.data;
			        json.labels = this.labels;
			        json.alpha = this.alpha;
			      }
	
			      return json;
			    },
			    
			    fromJSON: function(json) {
			      
			      this.N = json.N;
			      this.D = json.D;
			      this.b = json.b;
	
			      this.kernelType = json.kernelType;
			      if(this.kernelType === "linear") { 
	
			        // load the weights! 
			        this.w = json.w; 
			        this.usew_ = true; 
			        this.kernel = linearKernel; // this shouldn't be necessary
			      }
			      else if(this.kernelType == "rbf") {
	
			        // initialize the kernel
			        this.rbfSigma = json.rbfSigma; 
			        this.kernel = makeRbfKernel(this.rbfSigma);
	
			        // load the support vectors
			        this.data = json.data;
			        this.labels = json.labels;
			        this.alpha = json.alpha;
			      } else {
			        console.log("ERROR! unrecognized kernel type." + this.kernelType);
			      }
			    }
			  }
			  
			  // Kernels
			  function makeRbfKernel(sigma) {
			    return function(v1, v2) {
			      var s=0;
			      for(var q=0;q<v1.length;q++) { s += (v1[q] - v2[q])*(v1[q] - v2[q]); } 
			      return Math.exp(-s/(2.0*sigma*sigma));
			    }
			  }
			  
			  function linearKernel(v1, v2) {
			    var s=0; 
			    for(var q=0;q<v1.length;q++) { s += v1[q] * v2[q]; } 
			    return s;
			  }
	
			  // Misc utility functions
			  // generate random floating point number between a and b
			  function randf(a, b) {
			    return Math.random()*(b-a)+a;
			  }
	
			  // generate random integer between a and b (b excluded)
			  function randi(a, b) {
			     return Math.floor(Math.random()*(b-a)+a);
			  }
	
			  // create vector of zeros of length n
			  function zeros(n) {
			    var arr= new Array(n);
			    for(var i=0;i<n;i++) { arr[i]= 0; }
			    return arr;
			  }
	
			  // export public members
			  exports = exports || {};
			  exports.SVM = SVM;
			  exports.makeRbfKernel = makeRbfKernel;
			  exports.linearKernel = linearKernel;
			  return exports;
	
			})(typeof module != 'undefined' && module.exports);  // add exports to module.exports if in node.js
			
		</script>
		
		
		
		<!-- Obtained IRIS dataset from python and split it into training and test sets. -->		
		<!-- Using only versicolor and virginica species -->
		<script>
		
			irisDataTrain = [[1.5, 4.5, 3.0, 5.6],
			                 [1.7, 5.0, 3.0, 6.7],
			                 [1.6, 4.5, 3.4, 6.0],
			                 [1.5, 4.7, 3.1, 6.7],
			                 [1.9, 5.1, 2.7, 5.8],
			                 [2.4, 5.6, 3.1, 6.7],
			                 [2.1, 5.6, 2.8, 6.4],
			                 [1.8, 4.8, 2.8, 6.2],
			                 [2.3, 6.9, 2.6, 7.7],
			                 [1.3, 4.2, 2.9, 5.7],
			                 [1.8, 5.6, 2.9, 6.3],
			                 [2.3, 5.7, 3.2, 6.9],
			                 [1.9, 6.1, 2.8, 7.4],
			                 [1.9, 5.3, 2.7, 6.4],
			                 [1.5, 4.5, 2.2, 6.2],
			                 [2.3, 5.1, 3.1, 6.9],
			                 [1.8, 6.3, 2.9, 7.3],
			                 [2.3, 5.2, 3.0, 6.7],
			                 [2.2, 5.8, 3.0, 6.5],
			                 [2.1, 6.6, 3.0, 7.6],
			                 [1.5, 4.5, 2.9, 6.0],
			                 [2.1, 5.9, 3.0, 7.1],
			                 [1.4, 5.6, 2.6, 6.1],
			                 [2.1, 5.4, 3.1, 6.9],
			                 [1.3, 4.1, 2.8, 5.7],
			                 [1.8, 5.5, 3.1, 6.4],
			                 [1.3, 4.4, 2.3, 6.3],
			                 [1.1, 3.0, 2.5, 5.1],
			                 [1.6, 5.1, 2.7, 6.0],
			                 [1.0, 3.3, 2.3, 5.0],
			                 [1.0, 3.3, 2.4, 4.9],
			                 [2.1, 5.5, 3.0, 6.8],
			                 [1.8, 5.1, 3.0, 5.9],
			                 [1.0, 3.5, 2.6, 5.7],
			                 [1.5, 5.0, 2.2, 6.0],
			                 [1.9, 5.1, 2.7, 5.8],
			                 [1.5, 4.5, 3.2, 6.4],
			                 [2.0, 5.1, 3.2, 6.5],
			                 [2.0, 5.0, 2.5, 5.7],
			                 [1.5, 4.9, 3.1, 6.9],
			                 [1.8, 5.5, 3.0, 6.5],
			                 [1.5, 4.9, 2.5, 6.3],
			                 [2.0, 6.4, 3.8, 7.9],
			                 [1.4, 4.8, 2.8, 6.8],
			                 [1.3, 3.6, 2.9, 5.6],
			                 [1.3, 4.0, 2.5, 5.5],
			                 [1.3, 4.2, 2.7, 5.6],
			                 [1.8, 4.8, 3.2, 5.9],
			                 [1.3, 4.1, 3.0, 5.6],
			                 [2.5, 5.7, 3.3, 6.7],
			                 [1.0, 3.5, 2.0, 5.0],
			                 [1.4, 4.6, 3.0, 6.1],
			                 [2.1, 5.7, 3.3, 6.7],
			                 [1.1, 3.9, 2.5, 5.6],
			                 [1.3, 4.0, 2.8, 6.1],
			                 [1.4, 4.7, 3.2, 7.0],
			                 [2.0, 6.7, 2.8, 7.7],
			                 [1.7, 4.5, 2.5, 4.9],
			                 [1.3, 4.0, 2.3, 5.5],
			                 [1.3, 4.3, 2.9, 6.4]];
				
			irisDataTest = [[2.3, 5.9, 3.2, 6.8],
			                [2.2, 6.7, 3.8, 7.7],
			                [1.6, 4.7, 3.3, 6.3],
			                [2.4, 5.1, 2.8, 5.8],
			                [1.9, 5.0, 2.5, 6.3],
			                [1.5, 5.1, 2.8, 6.3],
			                [2.3, 5.4, 3.4, 6.2],
			                [1.2, 4.0, 2.6, 5.8],
			                [1.4, 4.4, 3.0, 6.6],
			                [1.4, 4.4, 3.1, 6.7],
			                [1.8, 4.9, 3.0, 6.1],
			                [1.4, 3.9, 2.7, 5.2],
			                [2.0, 4.9, 2.8, 5.6],
			                [2.0, 5.2, 3.0, 6.5],
			                [1.5, 4.5, 3.0, 5.4],
			                [1.8, 6.0, 3.2, 7.2],
			                [2.2, 5.6, 2.8, 6.4],
			                [1.2, 4.7, 2.8, 6.1],
			                [2.5, 6.1, 3.6, 7.2],
			                [1.2, 4.2, 3.0, 5.7],
			                [1.8, 4.9, 2.7, 6.3],
			                [1.0, 4.0, 2.2, 6.0],
			                [1.3, 4.6, 2.9, 6.6],
			                [1.5, 4.6, 2.8, 6.5],
			                [1.6, 5.8, 3.0, 7.2],
			                [2.4, 5.6, 3.4, 6.3],
			                [1.0, 4.1, 2.7, 5.8],
			                [2.3, 5.3, 3.2, 6.4],
			                [1.3, 4.3, 2.9, 6.2],
			                [2.5, 6.0, 3.3, 6.3],
			                [1.1, 3.8, 2.4, 5.5],
			                [1.3, 4.5, 2.8, 5.7],
			                [1.4, 4.7, 2.9, 6.1],
			                [1.0, 3.7, 2.4, 5.5],
			                [1.8, 4.8, 3.0, 6.0],
			                [1.5, 4.2, 3.0, 5.9],
			                [1.8, 5.8, 2.5, 6.7],
			                [2.3, 6.1, 3.0, 7.7],
			                [1.2, 3.9, 2.7, 5.8],
			                [1.2, 4.4, 2.6, 5.5]];
				
			irisTargetTrain = [-1, -1, -1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,
			                   1,  1,  1, -1,  1,  1,  1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1,
			                   1,  1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1,
			                  -1,  1, -1, -1, -1,  1,  1, -1, -1];
			
			irisTargetTest = [ 1,  1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1,  1,  1, -1,  1,  1,
			                   -1,  1, -1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,
			                   1, -1,  1,  1, -1, -1];
			
			irisFeatureNames = ['Sepal Length (cm)', 'Sepal Width (cm)', 'Petal Length (cm)', 'Petal Width (cm)'];
			irisFeatureIDs = ['sepalLength', 'sepalWidth', 'petalLength', 'petalWidth'];
			
			irisFeatureMin = [0.5, 2.5, 1.5, 4.5];
			irisFeatureMax = [3.0, 7.0, 4.0, 8.0];
			
			
			
		</script>

		<script>
		
			$(document).ready(function(){
				
// 				$('#content').text(irisTargetTest)
// 				$('#content2').text(testlabels)
				
				twoFeatureScatterPlotter(irisDataTrain, irisTargetTrain, 1, 3);
				
				// All Features
				
				predictions = allFeatures(parseFloat($('#parameterC').val()), $('#parameterKernel').val(), parseFloat($('#parameterRBFSigma').val()));				
				accuracy = predictionAccuracy(irisTargetTest, predictions);
				$('#allFeatureModel').text('Prediction accuracy = ' + accuracy + '%');
				
				
				function reEvaluate()
				{
				// Three Features
				
				
				removedFeatures = [];
				threeFeatureAccuracies = [];
				threeFeatureIndices = [];
				$('#threeFeatureModel').text('')
				
				for(i=0; i<4; i++)
				{
					trainingData = [];
					testingData = [];
										
					for(rowIndex in irisDataTrain)
					{
						newRow = [];
						for(j=0; j<4; j++)
						{
							if(i == j)
								continue;
							
							newRow.push(irisDataTrain[rowIndex][j]);
						}
						
						trainingData.push(newRow);
					}
					
					for(rowIndex in irisDataTest)
					{
						newRow = [];
						for(j=0; j<4; j++)
						{
							if(i == j)
								continue;
							
							newRow.push(irisDataTest[rowIndex][j]);
						}
						
						testingData.push(newRow);
					}
					
					svm = new svmjs.SVM();
					svm.train(trainingData, irisTargetTrain, {C: parseFloat($('#parameterC').val()), kernel: $('#parameterKernel').val(), rbfsigma: parseFloat($('#parameterRBFSigma').val())});
					predictions = svm.predict(testingData);
					accuracy = predictionAccuracy(irisTargetTest, predictions);
					threeFeatureAccuracies.push(accuracy);
					threeFeatureIndices.push(i);														
					
					$('#threeFeatureModel').append('Feature "' + irisFeatureNames[i] + '" removed, Prediction accuracy = ' + accuracy + '%<br>');					
				}
				worstThreeFeatureIndex = threeFeatureAccuracies.indexOf(Math.min.apply(null, threeFeatureAccuracies));
				removedFeatures.push(worstThreeFeatureIndex)
				$('#threeFeatureModel').append('<br><br>Feature providing least performance gain = "' + irisFeatureNames[worstThreeFeatureIndex] + '"<br>');
				$('#threeFeatureModel').append('It will be removed from the dataset.');
				
				
				// Two Features
				twoFeatureAccuracies = [];
				twoFeatureIndices = [];
				$('#twoFeatureModel').text('')
				
				for(i=0; i<4; i++)
				{
					if(i == removedFeatures[0])
						continue;
					
					trainingData = [];
					testingData = [];
										
					for(rowIndex in irisDataTrain)
					{
						newRow = [];
						for(j=0; j<4; j++)
						{
							if(i == j)
								continue;
							
							if(j == removedFeatures[0])
								continue;
							
							newRow.push(irisDataTrain[rowIndex][j]);
						}
						
						trainingData.push(newRow);
					}
					
					for(rowIndex in irisDataTest)
					{
						newRow = [];
						for(j=0; j<4; j++)
						{
							if(i == j)
								continue;
							
							if(j == removedFeatures[0])
								continue;
							
							newRow.push(irisDataTest[rowIndex][j]);
						}
						
						testingData.push(newRow);
					}
					
					svm = new svmjs.SVM();
					svm.train(trainingData, irisTargetTrain, {C: parseFloat($('#parameterC').val()), kernel: $('#parameterKernel').val(), rbfsigma: parseFloat($('#parameterRBFSigma').val())});
					predictions = svm.predict(testingData);
					accuracy = predictionAccuracy(irisTargetTest, predictions);
					twoFeatureAccuracies.push(accuracy);
					twoFeatureIndices.push(i);					
					
					
					$('#twoFeatureModel').append('Feature "' + irisFeatureNames[i] + '" removed, Prediction accuracy = ' + accuracy + '%<br>');					
				}
				worstTwoFeatureIndex = twoFeatureIndices[twoFeatureAccuracies.indexOf(Math.min.apply(null, twoFeatureAccuracies))];
				removedFeatures.push(worstTwoFeatureIndex)
				$('#twoFeatureModel').append('<br><br>Feature providing least performance gain = "' + irisFeatureNames[removedFeatures[worstTwoFeatureIndex]] + '"<br>');
				$('#twoFeatureModel').append('It will be removed from the dataset.');
				
				
				
				// One Features
				oneFeatureAccuracies = [];
				oneFeatureIndices = [];
				$('#oneFeatureModel').text('')
				
				for(i=0; i<4; i++)
				{
					if(i == removedFeatures[0])
						continue;
					
					if(i == removedFeatures[1])
						continue;
					
					trainingData = [];
					testingData = [];
										
					for(rowIndex in irisDataTrain)
					{
						newRow = [];
						for(j=0; j<4; j++)
						{
							if(i == j)
								continue;
							
							if(j == removedFeatures[0])
								continue;
							
							if(j == removedFeatures[1])
								continue;
							
							newRow.push(irisDataTrain[rowIndex][j]);
						}
						
						trainingData.push(newRow);
					}
					
					for(rowIndex in irisDataTest)
					{
						newRow = [];
						for(j=0; j<4; j++)
						{
							if(i == j)
								continue;
							
							if(j == removedFeatures[0])
								continue;
							
							if(j == removedFeatures[1])
								continue;
							
							newRow.push(irisDataTest[rowIndex][j]);
						}
						
						testingData.push(newRow);
					}
					
					svm = new svmjs.SVM();
					svm.train(trainingData, irisTargetTrain, {C: parseFloat($('#parameterC').val()), kernel: $('#parameterKernel').val(), rbfsigma: parseFloat($('#parameterRBFSigma').val())});
					predictions = svm.predict(testingData);
					accuracy = predictionAccuracy(irisTargetTest, predictions);
					oneFeatureAccuracies.push(accuracy);
					oneFeatureIndices.push(i);					
					
					
					$('#oneFeatureModel').append('Feature "' + irisFeatureNames[i] + '" removed, Prediction accuracy = ' + accuracy + '%<br>');					
				}
				worstOneFeatureIndex = oneFeatureIndices[oneFeatureAccuracies.indexOf(Math.min.apply(null, oneFeatureAccuracies))];
				removedFeatures.push(worstOneFeatureIndex)
				$('#oneFeatureModel').append('<br><br>Feature providing least performance gain = "' + irisFeatureNames[worstOneFeatureIndex] + '"<br>');
				$('#oneFeatureModel').append('It will be removed from the dataset.');
				
				// RFE Order
				for(i=0; i<4; i++)
				{
					notFound = true;
					for(index in removedFeatures)
					{
						if(removedFeatures[index] == i)
						{
							notFound = false;
						}
					}
					
					if(notFound)
					{
						removedFeatures.push(i);
						continue;
					}
				}
				
				
				$('#featureOrder').html('Order of features (lowest to highest importance) <br><br>')
				for(index in removedFeatures)
				{
					temp = parseInt(index) + 1
					$('#featureOrder').append(temp + '. ' + irisFeatureNames[removedFeatures[index]] + '<br>')
				}
				
				}
				
				reEvaluate();
				
				
				$('#scatterTwoFeatureX').change(function(){
					
					twoFeatureScatterPlotter(irisDataTrain, irisTargetTrain, parseInt($('#scatterTwoFeatureX').val()), parseInt($('#scatterTwoFeatureY').val()));
					
				});
				
				$('#scatterTwoFeatureY').change(function(){
					
					twoFeatureScatterPlotter(irisDataTrain, irisTargetTrain, parseInt($('#scatterTwoFeatureX').val()), parseInt($('#scatterTwoFeatureY').val()));
					
				});
				
				$('#parameterC').change(function(){
					
					
					predictions = allFeatures(parseFloat($('#parameterC').val()), $('#parameterKernel').val(), parseFloat($('#parameterRBFSigma').val()));				
					accuracy = predictionAccuracy(irisTargetTest, predictions);
					$('#allFeatureModel').text('Prediction accuracy = ' + accuracy + '%');
									
					reEvaluate();
				});
				
				$('#parameterKernel').change(function(){
					
					if($('#parameterKernel').val() == 'rbf')
					{
						$('#parameterRBFSigma').show()	
						$('#rbfsigma').show()	
					}
					else
					{
						$('#parameterRBFSigma').hide()	
						$('#rbfsigma').hide()	
					}					
					
					predictions = allFeatures(parseFloat($('#parameterC').val()), $('#parameterKernel').val(), parseFloat($('#parameterRBFSigma').val()));				
					accuracy = predictionAccuracy(irisTargetTest, predictions);
					$('#allFeatureModel').text('Prediction accuracy = ' + accuracy + '%');
									
					reEvaluate();
				});
				
				$('#parameterRBFSigma').change(function(){
					
					
					predictions = allFeatures(parseFloat($('#parameterC').val()), $('#parameterKernel').val(), parseFloat($('#parameterRBFSigma').val()));				
					accuracy = predictionAccuracy(irisTargetTest, predictions);
					$('#allFeatureModel').text('Prediction accuracy = ' + accuracy + '%');
									
					
					reEvaluate();
				});
				
				
			});
		
		</script>

		<script type="text/javascript">
		
			function twoFeatureScatterPlotter(dataset, target, featureIndex1, featureIndex2)
			{
				dataSubSet1 = [];
				dataSubSet2 = [];
				for(row in dataset)
				{
					if(target[row] == -1)
					{
						dataSubSet1.push({x: dataset[row][featureIndex1], y: dataset[row][featureIndex2]});	
					}
					else
					{
						dataSubSet2.push({x: dataset[row][featureIndex1], y: dataset[row][featureIndex2]});	
					}
				}
								
				var chart = new CanvasJS.Chart("irisTwoFeatureScatter",
				{
					axisX:{
						title: irisFeatureNames[featureIndex1],
						minimum: irisFeatureMin[featureIndex1],
						maximum: irisFeatureMax[featureIndex1]
					},
					axisY:{
						title: irisFeatureNames[featureIndex2],
						minimum: irisFeatureMin[featureIndex2],
						maximum: irisFeatureMax[featureIndex2]
					},
// 					legend:{
// 						verticalAlign: "bottom",
// 						horizontalAlign: "left"
// 					},
					data:[
						{
							type: "scatter",
							color: "#FF0000",
 							legendText: "Versicolor",
							showInLegend: "true",
							markerType: "circle",
							dataPoints: dataSubSet1
						},
						{
							type: "scatter",
							color: "#0000FF",
 							legendText: "Virgininca",
							showInLegend: "true",
							markerType: "circle",
							dataPoints: dataSubSet2
						}
					]
				});
					
				chart.render();
			}
			
 			function allFeatures(C, kernel, rbfSigma)
 			{
				svm = new svmjs.SVM();
				svm.train(irisDataTrain, irisTargetTrain, {C: C, kernel: kernel, rbfsigma: rbfSigma});
				return svm.predict(irisDataTest);
 			}
			
 			
 			function predictionAccuracy(trueOutcomes, predictedOutcomes)
 			{
 				correctPredictions = 0;
 				for(index in trueOutcomes)
 				{
 					if(trueOutcomes[index] == predictedOutcomes[index])
 						correctPredictions++;
 				}
 				return (correctPredictions/trueOutcomes.length*100.0);
 			}
 			
		</script>



	</head>

	<body>
	
		



		<div class = 'header'>
		
			Recursive Feature Elimination
		
		</div>
		



		<div style="margin-top: 50px"></div>
		



		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					SVM Parameters
				</div>
				
				<div class = 'sectionContent'>
				
					<table style="width: 100%">
					
						<tr>
							<td>C</td>
							<td>Kernel</td>
							<td><span id='rbfsigma'>RBF Sigma</span></td>
						</tr>
						<tr>
							<td width = "33%">
								<select name="parameterC" id="parameterC">
									<option value="0.01">0.01</option>
									<option value="0.1">0.1</option>
									<option value="1" selected="selected">1</option>
									<option value="10">10</option>
									<option value="100">100</option>
								</select>
							</td>
							<td width = "33%">
								<select name="parameterKernel" id="parameterKernel">
									<option value="linear">Linear</option>
									<option value="rbf" selected="selected">RBF</option>
								</select>
							</td>
							<td>
								<select name="parameterRBFSigma" id="parameterRBFSigma">
									<option value="0.01">0.01</option>
									<option value="0.1">0.1</option>
									<option value="1" selected="selected">1</option>
									<option value="10">10</option>
									<option value="100">100</option>
								</select>
							</td>
						</tr>						
					
					</table>					  					  						  			
				</div>			
				
			 	<br>
				
			</div>
		</div>





		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					Step 1: Model with all features
				</div>
				
				<div class = 'sectionContent'>				
					<p id='allFeatureModel'></p>					  				
				</div>
							
			</div>
		</div>





		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					Step 2: Model with three features (One feature removed)
				</div>
				
				<div class = 'sectionContent'>
					<p id='threeFeatureModel'></p>			
				</div>
							
			</div>
		</div>





		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					Step 3: Model with two features (Two features removed)
				</div>
				
				<div class = 'sectionContent'>
					<p id='twoFeatureModel'></p>			
				</div>
							
			</div>
		</div>





		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					Two Features
				</div>
				
				<div class = 'sectionContent'>
				
					<div id="irisTwoFeatureScatter" style="height: 500px; width: 100%;">
					</div>
					
					<br>
					
					<div>
						<H4>X Axis</H4>
						<select name="scatterTwoFeatureX" id="scatterTwoFeatureX">
							<option value="0">Sepal Length (cm)</option>
							<option value="1" selected="selected">Sepal Width (cm)</option>
							<option value="2">Petal Length (cm)</option>
							<option value="3">Petal Width (cm)</option>
						</select>
						<br>
						<br>
						<H4>Y Axis</H4>
						<select name="scatterTwoFeatureY" id="scatterTwoFeatureY">
							<option value="0">Sepal Length (cm)</option>
							<option value="1">Sepal Width (cm)</option>
							<option value="2">Petal Length (cm)</option>
							<option value="3" selected="selected">Petal Width (cm)</option>
						</select>
					</div>					 
					  				
				</div>
							
			</div>
		</div>





		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					Step 4: Model with one feature (Three features removed)
				</div>
				
				<div class = 'sectionContent'>
					<p id='oneFeatureModel'></p>			
				</div>
							
			</div>
		</div>



		<div class = 'sectionMain'>
			<div class = 'section'>
		
				<div class = 'sectionHeader'>
					RFE Feature Order
				</div>
				
				<div class = 'sectionContent'>
					<p id='featureOrder'></p>			
				</div>
							
			</div>
		</div>


		<footer>
		Special thanks to GitHub user Andrej Karpathy for SVM-JS code. Link: <a style="color: yellow;" href="https://github.com/karpathy/svmjs">Click Here</a>
		</footer>


<!-- 		<p id='content'></p> -->
<!-- 		<p id='content2'></p> -->

	
	</body>

</html>